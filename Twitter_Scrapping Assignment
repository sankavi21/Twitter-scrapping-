import snscrape.modules.twitter as sntwitter
import pandas as pd
import pymongo
import streamlit as st
from datetime import date


st.subheader("Scrape any tweets")



def scrape_tweets(query, num_tweets):
    # Create empty list to hold tweet data
    tweets_list = []
    
    # Use snscrape to get the tweets
    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query + ' since:2020-01-01 until:2023-02-26').get_items()):
        if i >= num_tweets:
            break
        tweets_list.append([tweet.date,
                            tweet.id,
                            tweet.url,
                            tweet.rawContent,
                            tweet.user.username,
                            tweet.replyCount,
                            tweet.retweetCount,
                            tweet.likeCount,
                            tweet.lang,
                            tweet.source])
    
    # Create a Pandas dataframe from the list of tweets
    tweets_df = pd.DataFrame(tweets_list, columns=['datetime', 'user_id', 'url', 'tweet_content', 'user_name',
                                         'reply_count', 'retweet_count', 'like_count', 'language', 'source'])


    
    return tweets_df
query = 'python'
num_tweets = 100

tweets_df = scrape_tweets(query, num_tweets)
print(tweets_df)

